{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYKwldBwVXIW"
   },
   "source": [
    "# 1. 개인 구글 드라이브와 colab 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4014,
     "status": "ok",
     "timestamp": 1696466681460,
     "user": {
      "displayName": "김환희",
      "userId": "12914926509641772339"
     },
     "user_tz": -540
    },
    "id": "5o0lh-JLURY7",
    "outputId": "2dfa937d-0033-4c69-b7e6-14e5baa5ce14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/gdrive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "junjuA4pVM5n"
   },
   "source": [
    "# 2. 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6420,
     "status": "ok",
     "timestamp": 1696466703212,
     "user": {
      "displayName": "김환희",
      "userId": "12914926509641772339"
     },
     "user_tz": -540
    },
    "id": "WwzrDnJYmV3Z",
    "outputId": "6b85242f-6b73-4174-8f2b-c54fa78aab43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (0.3.6)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (0.9.9)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (1.16.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlLEwntGYHKn"
   },
   "source": [
    "# 3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "1. 데이터셋에서 json 파일을 불러온다.\n",
    "2. 데이터셋의 json 파일에서 카테고리별로 named_entity 항목의 content를 가져온다.\n",
    "3. 카테고리별 합의 비율별에 랜덤하게 문장 1만개를 뽑는다.\n",
    "4. content의 띄어쓰기 정보를 이용해 각 content에 대응하는 띄어쓰기 레이블을 가져온다.\n",
    "\n",
    "결과물:\n",
    "train_datas\n",
    "    ㄴ category\n",
    "        ㄴ sentences\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "RAW_TRAIN_PATH = './rawDataset'\n",
    "TRAIN_PATH = './dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(source_path, new_path):\n",
    "    categories = os.listdir(path=source_path) # 건강, 경제, 교육, ...\n",
    "    print(categories)\n",
    "    \n",
    "    for category in categories:\n",
    "        for filename in os.listdir(os.path.join(source_path, category)):\n",
    "            result = []\n",
    "            \n",
    "            with open(os.path.join(source_path, category, filename), 'r', encoding='UTF-8') as source_file,\\\n",
    "                open(os.path.join(new_path, category + '_spacing_data.txt'), 'w', encoding='UTF-8-sig') as new_file:\n",
    "                \n",
    "                # Read\n",
    "                json_data = json.load(source_file)\n",
    "\n",
    "                for named_entity in json_data['named_entity']:\n",
    "                    for item in named_entity['content']:\n",
    "                        # Preprocess\n",
    "                        new_sample = item['sentence'][0] + ' '\n",
    "                        label = 'B '\n",
    "                        \n",
    "                        it = iter(item['sentence'])\n",
    "                        for idx, c in enumerate(item['sentence'][1:], 1):\n",
    "                            if c == ' ':\n",
    "                                continue\n",
    "                                \n",
    "                            new_sample += (c + ' ')\n",
    "                            if item['sentence'][idx - 1] == ' ':\n",
    "                                label += 'B '\n",
    "                            else:\n",
    "                                label += 'I '\n",
    "\n",
    "                        result = new_sample + '\\t' + label + '\\n'\n",
    "                            \n",
    "                        # Write\n",
    "                        new_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IT_과학', '건강', '경제', '교육', '국제', '라이프스타일', '문화', '사건사고', '사회일반', '산업', '스포츠', '여성복지', '여행레저', '연예', '정치', '지역', '취미']\n",
      "imported sentences of train_datas completely\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "preprocess_data(RAW_TRAIN_PATH, TRAIN_PATH)\n",
    "                    \n",
    "print(\"imported sentences of train_datas completely\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_num(path, target_num):\n",
    "    file_lines = {}\n",
    "    total_lines = 0\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        with open(os.path.join(path, filename), 'r',  encoding='UTF-8') as file:\n",
    "            lines = file.readlines()\n",
    "            file_lines[filename] = len(lines)\n",
    "            total_lines += len(lines)\n",
    "    \n",
    "    target_lines = {}\n",
    "    total_target = 0\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        num_lines = file_lines[filename]\n",
    "        target_lines[filename] = round(num_lines * target_num / total_lines)    \n",
    "        total_target += target_lines[filename]\n",
    "\n",
    "    # Fine tuning\n",
    "    target_lines[os.listdir(path)[0]] += (target_num - total_target)\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        num_lines = file_lines[filename]\n",
    "        pi = file_lines[filename] / total_lines\n",
    "    \n",
    "    total_target = sum([target_lines[filename] for filename in os.listdir(path)])\n",
    "    return target_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IT_과학_spacing_data.txt': 952, '건강_spacing_data.txt': 1048, '경제_spacing_data.txt': 817, '교육_spacing_data.txt': 569, '국제_spacing_data.txt': 655, '라이프스타일_spacing_data.txt': 210, '문화_spacing_data.txt': 882, '사건사고_spacing_data.txt': 319, '사회일발_spacing_data.txt': 132, '산업_spacing_data.txt': 377, '스포츠_spacing_data.txt': 902, '여성복지_spacing_data.txt': 685, '여행레저_spacing_data.txt': 496, '연예_spacing_data.txt': 635, '정치_spacing_data.txt': 308, '지역_spacing_data.txt': 434, '취미_spacing_data.txt': 579}\n",
      "total: 10000\n"
     ]
    }
   ],
   "source": [
    "# Set dataset num\n",
    "dataset_num = get_dataset_num(TRAIN_PATH, 10000)\n",
    "print(dataset_num)\n",
    "\n",
    "print(f\"total: {sum([dataset_num[filename] for filename in dataset_num])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUf7YKTATa8G"
   },
   "source": [
    "<pre>\n",
    "1. 문장과 라벨을 튜플형태로 datas 리스트에 넣는다\n",
    "    datas = [ ( [\"나\", \"는\", \"사\", \"과\", \"가\", \"좋\", \"아\"], [\"B\", \"I\", \"B\", \"I\", \"I\", \"B\", \"I\"] ), ( ... ), ... ]\n",
    "\n",
    "2. 전체 데이터를 분류 비율에 맞추어, 테스트-검증 9:1 비율에 맞추어 학습, 평가 데이터로 나누기\n",
    "  train_datas 리스트와 test_datas 리스트에 나누어 저장\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1817,
     "status": "ok",
     "timestamp": 1696466710606,
     "user": {
      "displayName": "김환희",
      "userId": "12914926509641772339"
     },
     "user_tz": -540
    },
    "id": "0VJD-PF6dYfb",
    "outputId": "b521989e-a909-4887-8a59-6c1a4ffc2478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_datas 개수 : 9000\n",
      "test_datas 개수 : 1000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_datas = []\n",
    "test_datas = []\n",
    "\n",
    "for filename in os.listdir(TRAIN_PATH):\n",
    "    # 파일을 읽고 lines에 읽은 데이터를 저장\n",
    "    with open(os.path.join(TRAIN_PATH, filename), \"r\", encoding=\"utf8\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # 데이터를 음절로 이루어진 문장과 정답 값으로 나누어 저장\n",
    "    datas = []\n",
    "\n",
    "    # 데이터 개수 10000개로 맞추기\n",
    "    lines = random.sample(lines, dataset_num[filename])\n",
    "    for line in lines:\n",
    "        pieces = line.strip().split('\\t')\n",
    "        eumjeol_sequence, label = pieces[0].split(), pieces[1].split()\n",
    "        datas.append((eumjeol_sequence, label))\n",
    "    \n",
    "    number_of_train_datas = round(len(datas)*0.9)\n",
    "    \n",
    "    train_datas += datas[:number_of_train_datas]\n",
    "    test_datas += datas[number_of_train_datas:]\n",
    "\n",
    "print(\"train_datas 개수 : \" + str(len(train_datas)))\n",
    "print(\"test_datas 개수 : \" + str(len(test_datas)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoVhuFogkT36"
   },
   "source": [
    "<pre>\n",
    "1. 문장의 각 음절을 crf 모델의 입력으로 사용 할 수 있도록 자질화 </h2>\n",
    "  \"BOS\" : 시작 음절인지 여부\n",
    "  \"EOS\" : 마지막 음절인지 여부\n",
    "  \"WORD\" : 기준 음절\n",
    "  \"IS_DIGIT\" : 기준 음절이 숫자인지 여부\n",
    "  \"-1_WORD\" : 기준 음절의 왼쪽 첫번째 음절\n",
    "  \"-2_WORD\" : 기준 음절의 왼쪽 두번째 음절\n",
    "  \"+1_WORD\" : 기준 음절의 오른쪽 첫번째 음절\n",
    "  \"+2_WORD\" : 기준 음절의 오른쪽 두번째 음절\n",
    "\n",
    "    예시) [\"나\", \"는\", \"사\", \"과\", \"가\", \"좋\", \"아\"]\n",
    "         -> [\n",
    "    { \"BOS\":True, \"EOS\":False, \"WORD\":\"나\", \"IS_DIGIT\":False, \"+1_WORD\":\"는\", \"+2_WORD\":\"사\" },\n",
    "    { \"BOS\":False, \"EOS\":False, \"WORD\":\"는\", \"IS_DIGIT\":False, \"-1_WORD\":\"나\", \"+1_WORD\":\"사\", \"+2_WORD\":\"과\" },\n",
    "    { \"BOS\":False, \"EOS\":False, \"WORD\":\"사\", \"IS_DIGIT\":False, \"-2_WORD\":\"나\", \"-1_WORD\":\"는\", \"+1_WORD\":\"과\", \"+2_WORD\":\"가\" },\n",
    "    ... ]\n",
    "\n",
    "2. 자질화한 데이터와 해당 데이터의 라벨을 분리하여 각 리스트에 저장\n",
    "  학습 데이터 -> train_x(자질화한 데이터), train_y(각 데이터의 정답 라벨)에 저장\n",
    "  평가 데이터 -> test_x(자질화한 데이터), test_y(각 데이터의 정답 라벨)에 저장\n",
    "  \n",
    "    예시)\n",
    "    train_x -> [\n",
    "        [ { \"BOS\":True, \"EOS\":False, \"WORD\":\"나\", \"IS_DIGIT\":False, \"+1_WORD\":\"는\", \"+2_WORD\":\"사\" },\n",
    "        { \"BOS\":False, \"EOS\":False, \"WORD\":\"는\", \"IS_DIGIT\":False, \"-1_WORD\":\"나\", \"+1_WORD\":\"사\", \"+2_WORD\":\"과\" },\n",
    "        { \"BOS\":False, \"EOS\":False, \"WORD\":\"사\", \"IS_DIGIT\":False, \"-2_WORD\":\"나\", \"-1_WORD\":\"는\", \"+1_WORD\":\"과\", \"+2_WORD\":\"가\" },\n",
    "        ... ],\n",
    "        ...\n",
    "    ]\n",
    "    \n",
    "    train_y -> [\n",
    "        [ \"B\", \"I\", \"B\", \"I\", \"I\", \"B\", \"I\" ],\n",
    "        ...\n",
    "    ]\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1696466728595,
     "user": {
      "displayName": "김환희",
      "userId": "12914926509641772339"
     },
     "user_tz": -540
    },
    "id": "UHfwBbtqSgAx"
   },
   "outputs": [],
   "source": [
    "def sent2feature(eumjeol_sequence):\n",
    "    features = []\n",
    "    sequence_length = len(eumjeol_sequence)\n",
    "    for index, eumjeol in enumerate(eumjeol_sequence):\n",
    "        feature = {\n",
    "            'BOS': False,\n",
    "            'EOS': False,\n",
    "            'WORD': eumjeol,\n",
    "            'IS_DIGIT':eumjeol.isdigit()\n",
    "        }\n",
    "\n",
    "        if index == 0:\n",
    "            feature[\"BOS\"] = True\n",
    "        elif index == sequence_length - 1:\n",
    "            feature['EOS'] = True\n",
    "\n",
    "        if index - 1 >= 0:\n",
    "            feature['-1_WORD'] = eumjeol_sequence[index - 1]\n",
    "        if index - 2 >= 0:\n",
    "            feature['-2_WORD'] = eumjeol_sequence[index - 2]\n",
    "\n",
    "        if index + 1 <= sequence_length - 1:\n",
    "            feature['+1_WORD'] = eumjeol_sequence[index + 1]\n",
    "        if index + 2 <= sequence_length - 2:\n",
    "            feature['+2_WORD'] = eumjeol_sequence[index + 2]\n",
    "\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "\n",
    "train_x, train_y = [], []\n",
    "for eumjeol_sequence, label in train_datas:\n",
    "    train_x.append(sent2feature(eumjeol_sequence))\n",
    "    train_y.append(label)\n",
    "\n",
    "test_x, test_y = [], []\n",
    "for eumjeol_sequence, label in test_datas:\n",
    "    test_x.append(sent2feature(eumjeol_sequence))\n",
    "    test_y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1696466730431,
     "user": {
      "displayName": "김환희",
      "userId": "12914926509641772339"
     },
     "user_tz": -540
    },
    "id": "uKtZF6asOMVT",
    "outputId": "a799930a-fb16-4152-8a44-8918a720fcbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프 -> {'BOS': False, 'EOS': False, 'WORD': '프', 'IS_DIGIT': False, '-1_WORD': '망', '-2_WORD': '경', '+1_WORD': '로', '+2_WORD': '세'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{train_x[0][9]['WORD']} -> {train_x[0][9]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYwRX9Vdn5-D"
   },
   "source": [
    "# 3. train_x, train_y를 이용하여 crf 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1285,
     "status": "ok",
     "timestamp": 1696466760575,
     "user": {
      "displayName": "김환희",
      "userId": "12914926509641772339"
     },
     "user_tz": -540
    },
    "id": "odbrhxSKStT-"
   },
   "outputs": [],
   "source": [
    "#crf = sklearn_crfsuite.CRF(\n",
    "#        algorithm='lbfgs',\n",
    "#        c1=0.1,\n",
    "#        c2=0.1,\n",
    "#        max_iterations=100,\n",
    "#        all_possible_transitions=True\n",
    "#    )\n",
    "\n",
    "crf = sklearn_crfsuite.CRF()\n",
    "try:\n",
    "    crf.fit(train_x, train_y)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07BbK76nuZVK"
   },
   "source": [
    "<pre>\n",
    "1. 학습한 모델을 test_x 데이터를 사용하여 평가\n",
    "2. 성능 측정\n",
    "    metrics.flat_accuracy_score(x, y) 함수를 이용하여 성능 측정\n",
    "  \n",
    "3. 모델의 출력 값과 정답 값을 이용하여 음절만으로 구성된 완전한 문장으로 변형\n",
    "    예시)\n",
    "    정답 문장 : 하지만 이 전쟁은 죽음을 통해 인류를 통합시켰다.\n",
    "    출력 문장 : 하지만이 전쟁은 죽음을 통해 인류를 통합시켰다.\n",
    "    ...\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1696466764533,
     "user": {
      "displayName": "김환희",
      "userId": "12914926509641772339"
     },
     "user_tz": -540
    },
    "id": "hgIPGK--SzmA",
    "outputId": "dd4d0849-2367-4b68-e976-dca98079b534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.9240051256496049\n",
      "\n",
      "10개의 데이터에 대한 모델 출력과 실제 정답 비교\n",
      "\n",
      "정답 문장 : 특히 애플은 리튬이온 배터리를 교체하기만 해도 아이폰 성능이 70% 가량 복구될 수 있단 사실을 알리지 않은 점을 꼬집었다.\n",
      "출력 문장 : 특히 애플은 리튬이 온배터리를 교체하기 만해도 아이폰 성능이 70% 가량 복구될 수 있단 사실을 알리지 않은 점을 꼬집었다.\n",
      "\n",
      "정답 문장 : 이때 무인항공기가 촬영한 열 화상 (이름)가 방 어디에 누가 있는 지를 알려준다.”.\n",
      "출력 문장 : 이 때무인 항공기가 촬영한 열화상 (이름)가 방어디에 누가 있는 지를 알려준다.”.\n",
      "\n",
      "정답 문장 : 그는 그 (이름) “업그레이드하는 추가 이점이 크지 않기 때문”이라고 설명했다..\n",
      "출력 문장 : 그는 그 (이름) “업그레이드하는 추가 이점이 크지 않기 때문”이라고 설명했다..\n",
      "\n",
      "정답 문장 : 다만 원본 음원이 16비트이거나 24비트라 해도 처리 비트 수가 늘어나면 다이나믹 레인지가 증가하고 해상도가 높아지므로 음질 향상에는 기여할 것이라 본다.\".\n",
      "출력 문장 : 다만 원본 음원이 16비트이 거나 24비트라해도 처리비트수가 늘어나면다이 나믹레인지가 증가하고 해상도가 높아지므로 음질 향상에는 기여할 것이라본다.\".\n",
      "\n",
      "정답 문장 : #문제는 애플이다.\n",
      "출력 문장 : #문제는 애플이다.\n",
      "\n",
      "정답 문장 : 두 기업은 이같은 전략으로 흑자 전환과 수익 확대를 달성하겠다고 밝혔다.\n",
      "출력 문장 : 두기업은 이 같은 전략으로 흑자 전환과 수익 확대를 달성하겠다고 밝혔다.\n",
      "\n",
      "정답 문장 : 또 애플이 고의로 다른 사람의 자산에 개입해서 가치를 떨어뜨린 사실을 숨긴 점 역시 문제 삼았다..\n",
      "출력 문장 : 또 애플이고 의로 다른 사람의 자산에 개입해서 가치를 떨어뜨린 사실을 숨긴 점역 시문제삼았다..\n",
      "\n",
      "정답 문장 : 플랫폼 보안에선 ▲설정값 및 실행코드 무결성 검증 ▲안전한 업데이트 ▲감사기록을 요구했다.\n",
      "출력 문장 : 플랫폼 보안에선 ▲설정값 및 실행코드무 결성 검증 ▲안전 한업데 이트 ▲감사기록을 요구했다.\n",
      "\n",
      "정답 문장 : 명절이면 와인이나 양주 등 고급 술을 선물 받는 부모님을 위해 와인의 맛을 지켜주는 와인 냉장고를 선물하는 것은 어떨까..\n",
      "출력 문장 : 명절이면와 인이 나양주 등고 급술을 선물받는 부모님을 위해와 인의 맛을 지켜주는 와인 냉장고를 선물하는 것은 어떨까..\n",
      "\n",
      "정답 문장 : 즉, ca 인증을 받지 않았다고 해서 구매선 상에서 배제할 필요는 없는 셈이다..\n",
      "출력 문장 : 즉, ca인증을 받지 않았다고 해서 구매 선상에서 배제할 필요는 없는 셈이다..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_predict_result(test_datas, predict):\n",
    "  for index_1 in range(len(test_datas)):\n",
    "      eumjeol_sequence, correct_labels = test_datas[index_1]\n",
    "      predict_labels = predict[index_1]\n",
    "\n",
    "      correct_sentence, predict_sentence = \"\", \"\"\n",
    "      for index_2 in range(len(eumjeol_sequence)):\n",
    "          if(index_2 == 0):\n",
    "              correct_sentence += eumjeol_sequence[index_2]\n",
    "              predict_sentence += eumjeol_sequence[index_2]\n",
    "              continue\n",
    "\n",
    "          if(correct_labels[index_2] == \"B\"):\n",
    "              correct_sentence += \" \"\n",
    "          correct_sentence += eumjeol_sequence[index_2]\n",
    "\n",
    "          if (predict_labels[index_2] == \"B\"):\n",
    "              predict_sentence += \" \"\n",
    "          predict_sentence += eumjeol_sequence[index_2]\n",
    "\n",
    "      print(\"정답 문장 : \" + correct_sentence)\n",
    "      print(\"출력 문장 : \" + predict_sentence)\n",
    "      print()\n",
    "\n",
    "predict = crf.predict(test_x)\n",
    "\n",
    "print(\"Accuracy score : \" + str(metrics.flat_accuracy_score(test_y, predict)))\n",
    "print()\n",
    "\n",
    "print(\"10개의 데이터에 대한 모델 출력과 실제 정답 비교\")\n",
    "print()\n",
    "\n",
    "show_predict_result(test_datas[:10], predict[:10])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
